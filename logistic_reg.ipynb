{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get needed data\n",
    "\n",
    "# Training data\n",
    "data_sampled_extrovert = pd.read_csv('data/df_extrovert_introvert_joined_sampled.csv')\n",
    "data_sampled_feeling = pd.read_csv('data/df_feeling_thinking_joined_sampled.csv')\n",
    "data_sampled_judging = pd.read_csv('data/df_judging_perceiving_joined_sampled.csv')\n",
    "data_sampled_sensing = pd.read_csv('data/df_sensing_intuitive_joined_sampled.csv')\n",
    "\n",
    "# Test data\n",
    "data_test = pd.read_csv('data/personality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post_extrovert</th>\n",
       "      <th>extrovert</th>\n",
       "      <th>post_feeling</th>\n",
       "      <th>feeling</th>\n",
       "      <th>post_judging</th>\n",
       "      <th>judging</th>\n",
       "      <th>post_sensing</th>\n",
       "      <th>sensing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_12bhu7</td>\n",
       "      <td>I wear a Lorna shore shirt out alot in public ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I wear a Lorna shore shirt out alot in public ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I wear a Lorna shore shirt out alot in public ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I wear a Lorna shore shirt out alot in public ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_12jbpd</td>\n",
       "      <td>I'd say this is a very accurate characterizati...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'd say this is a very accurate characterizati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I'd say this is a very accurate characterizati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I'd say this is a very accurate characterizati...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_12uwr5</td>\n",
       "      <td>Ya know like most people with home decorations...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ya know like most people with home decorations...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ya know like most people with home decorations...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ya know like most people with home decorations...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_12zm15</td>\n",
       "      <td>It's true tho. They're kinda more interesting ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>It's true tho. They're kinda more interesting ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It's true tho. They're kinda more interesting ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>It's true tho. They're kinda more interesting ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_13cjjl</td>\n",
       "      <td>Yeah, but that's one of the things that make m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yeah, but that's one of the things that make m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yeah, but that's one of the things that make m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yeah, but that's one of the things that make m...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>t2_vfp8y</td>\n",
       "      <td>so change profession then. this would be inadm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>so change profession then. this would be inadm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>so change profession then. this would be inadm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>so change profession then. this would be inadm...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>t2_w0842</td>\n",
       "      <td>The technological singularity. And the possibi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The technological singularity. And the possibi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The technological singularity. And the possibi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The technological singularity. And the possibi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>t2_w6rgl</td>\n",
       "      <td>Dear God man. Chill. I'm not Einstein or Hawki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dear God man. Chill. I'm not Einstein or Hawki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dear God man. Chill. I'm not Einstein or Hawki...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dear God man. Chill. I'm not Einstein or Hawki...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>t2_wilcwvo</td>\n",
       "      <td>That's what a fake lib would say [Human blood ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>That's what a fake lib would say [Human blood ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>That's what a fake lib would say [Human blood ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>That's what a fake lib would say [Human blood ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>t2_zq7gkv</td>\n",
       "      <td>My biggest problem is asking for it. I don’t n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My biggest problem is asking for it. I don’t n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My biggest problem is asking for it. I don’t n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My biggest problem is asking for it. I don’t n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      auhtor_ID                                     post_extrovert  extrovert  \\\n",
       "0     t2_12bhu7  I wear a Lorna shore shirt out alot in public ...        1.0   \n",
       "1     t2_12jbpd  I'd say this is a very accurate characterizati...        1.0   \n",
       "2     t2_12uwr5  Ya know like most people with home decorations...        0.0   \n",
       "3     t2_12zm15  It's true tho. They're kinda more interesting ...        0.0   \n",
       "4     t2_13cjjl  Yeah, but that's one of the things that make m...        0.0   \n",
       "..          ...                                                ...        ...   \n",
       "150    t2_vfp8y  so change profession then. this would be inadm...        0.0   \n",
       "151    t2_w0842  The technological singularity. And the possibi...        0.0   \n",
       "152    t2_w6rgl  Dear God man. Chill. I'm not Einstein or Hawki...        0.0   \n",
       "153  t2_wilcwvo  That's what a fake lib would say [Human blood ...        1.0   \n",
       "154   t2_zq7gkv  My biggest problem is asking for it. I don’t n...        1.0   \n",
       "\n",
       "                                          post_feeling  feeling  \\\n",
       "0    I wear a Lorna shore shirt out alot in public ...      1.0   \n",
       "1    I'd say this is a very accurate characterizati...      0.0   \n",
       "2    Ya know like most people with home decorations...      0.0   \n",
       "3    It's true tho. They're kinda more interesting ...      1.0   \n",
       "4    Yeah, but that's one of the things that make m...      0.0   \n",
       "..                                                 ...      ...   \n",
       "150  so change profession then. this would be inadm...      0.0   \n",
       "151  The technological singularity. And the possibi...      0.0   \n",
       "152  Dear God man. Chill. I'm not Einstein or Hawki...      0.0   \n",
       "153  That's what a fake lib would say [Human blood ...      0.0   \n",
       "154  My biggest problem is asking for it. I don’t n...      1.0   \n",
       "\n",
       "                                          post_judging  judging  \\\n",
       "0    I wear a Lorna shore shirt out alot in public ...      0.0   \n",
       "1    I'd say this is a very accurate characterizati...      0.0   \n",
       "2    Ya know like most people with home decorations...      1.0   \n",
       "3    It's true tho. They're kinda more interesting ...      0.0   \n",
       "4    Yeah, but that's one of the things that make m...      0.0   \n",
       "..                                                 ...      ...   \n",
       "150  so change profession then. this would be inadm...      1.0   \n",
       "151  The technological singularity. And the possibi...      1.0   \n",
       "152  Dear God man. Chill. I'm not Einstein or Hawki...      1.0   \n",
       "153  That's what a fake lib would say [Human blood ...      0.0   \n",
       "154  My biggest problem is asking for it. I don’t n...      1.0   \n",
       "\n",
       "                                          post_sensing  sensing  \n",
       "0    I wear a Lorna shore shirt out alot in public ...      0.0  \n",
       "1    I'd say this is a very accurate characterizati...      0.0  \n",
       "2    Ya know like most people with home decorations...      0.0  \n",
       "3    It's true tho. They're kinda more interesting ...      0.0  \n",
       "4    Yeah, but that's one of the things that make m...      1.0  \n",
       "..                                                 ...      ...  \n",
       "150  so change profession then. this would be inadm...      0.0  \n",
       "151  The technological singularity. And the possibi...      0.0  \n",
       "152  Dear God man. Chill. I'm not Einstein or Hawki...      0.0  \n",
       "153  That's what a fake lib would say [Human blood ...      0.0  \n",
       "154  My biggest problem is asking for it. I don’t n...      0.0  \n",
       "\n",
       "[155 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dimit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dimit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# function to preprocess text, removing stopwords, punctuation, and converting to lowercase\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess both train and test data.\n",
    "\n",
    "data_sampled_extrovert['processed_post'] = data_sampled_extrovert['post'].apply(preprocess_text)\n",
    "data_sampled_feeling['processed_post'] = data_sampled_feeling['post'].apply(preprocess_text)\n",
    "data_sampled_judging['processed_post'] = data_sampled_judging['post'].apply(preprocess_text)\n",
    "data_sampled_sensing['processed_post'] = data_sampled_sensing['post'].apply(preprocess_text)\n",
    "\n",
    "data_test['processed_post'] = data_test['post_extrovert'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get BERT embeddings for a text and average them across tokens.\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to obtain BERT embeddings for a text\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize input text and convert to tensor\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(tokens)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # Average the embeddings across tokens (you can modify this based on your needs)\n",
    "    avg_embedding = torch.mean(embeddings, dim=1).squeeze().numpy()\n",
    "\n",
    "    return avg_embedding\n",
    "\n",
    "\n",
    "# Get BERT embeddings for all texts in the training and test data\n",
    "\n",
    "data_sampled_extrovert['bert_embeddings'] = data_sampled_extrovert['post'].apply(get_bert_embeddings)\n",
    "data_sampled_feeling['bert_embeddings'] = data_sampled_feeling['post'].apply(get_bert_embeddings)\n",
    "data_sampled_judging['bert_embeddings'] = data_sampled_judging['post'].apply(get_bert_embeddings)\n",
    "data_sampled_sensing['bert_embeddings'] = data_sampled_sensing['post'].apply(get_bert_embeddings)\n",
    "\n",
    "data_test['bert_embeddings'] = data_test['post_extrovert'].apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>extrovert</th>\n",
       "      <th>processed_post</th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_10j5wx</td>\n",
       "      <td>Mother told me not to lie... I don't care. I a...</td>\n",
       "      <td>1</td>\n",
       "      <td>mother told lie dont care actually want feel s...</td>\n",
       "      <td>[-0.0066083446, 0.019449212, 0.45059752, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_10yl6g2x</td>\n",
       "      <td>I had a couple guys try to bully me when I cam...</td>\n",
       "      <td>1</td>\n",
       "      <td>couple guys try bully came high school laughed...</td>\n",
       "      <td>[-0.060043834, 0.0022917464, 0.34724408, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_11a78w</td>\n",
       "      <td>bruh i thought this was a meme until i saw op'...</td>\n",
       "      <td>1</td>\n",
       "      <td>bruh thought meme saw ops replies dumb ways di...</td>\n",
       "      <td>[0.0384882, 1.7724233e-05, 0.51028645, 0.03368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_11dfyb</td>\n",
       "      <td>I look girly and I look boyish when I talk. I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>look girly look boyish talk look like femme fa...</td>\n",
       "      <td>[-0.10429687, 0.14243859, 0.4481033, 0.1055139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_11xick</td>\n",
       "      <td>With respect, I don’t see how this can be the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>respect dont see case unless working pretty sp...</td>\n",
       "      <td>[0.025919035, 0.15715231, 0.19118866, -0.01539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>t2_tjqum</td>\n",
       "      <td>I wanted to downvote because the thought of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>wanted downvote thought makes wan na move moon...</td>\n",
       "      <td>[-0.09599738, -0.20567349, 0.5923554, -0.21366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>t2_lfu7v</td>\n",
       "      <td>Best thing you can do is leave and come back. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>best thing leave come back corporations appare...</td>\n",
       "      <td>[0.05184198, 0.13914925, 0.4454035, -0.0802945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>t2_2b9mn0cu</td>\n",
       "      <td>I believe it's about getting fully psionic pop...</td>\n",
       "      <td>0</td>\n",
       "      <td>believe getting fully psionic pops bit loki li...</td>\n",
       "      <td>[0.009137345, 0.09711996, 0.3804123, 0.0716632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>t2_5bam0</td>\n",
       "      <td>2 for sure, not even close It's not \"difficult...</td>\n",
       "      <td>0</td>\n",
       "      <td>sure even close difficulty seeing obvious red ...</td>\n",
       "      <td>[-0.0021679848, 0.20878139, 0.35289097, 0.0358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>t2_5d9ilxmj</td>\n",
       "      <td>Niestety będzie to dalej betonować podziały na...</td>\n",
       "      <td>0</td>\n",
       "      <td>niestety bdzie dalej betonowa podziay na rynku...</td>\n",
       "      <td>[-0.035595752, 0.015442409, 0.39556208, -0.399...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auhtor_ID                                               post  \\\n",
       "0      t2_10j5wx  Mother told me not to lie... I don't care. I a...   \n",
       "1    t2_10yl6g2x  I had a couple guys try to bully me when I cam...   \n",
       "2      t2_11a78w  bruh i thought this was a meme until i saw op'...   \n",
       "3      t2_11dfyb  I look girly and I look boyish when I talk. I ...   \n",
       "4      t2_11xick  With respect, I don’t see how this can be the ...   \n",
       "..           ...                                                ...   \n",
       "795     t2_tjqum  I wanted to downvote because the thought of th...   \n",
       "796     t2_lfu7v  Best thing you can do is leave and come back. ...   \n",
       "797  t2_2b9mn0cu  I believe it's about getting fully psionic pop...   \n",
       "798     t2_5bam0  2 for sure, not even close It's not \"difficult...   \n",
       "799  t2_5d9ilxmj  Niestety będzie to dalej betonować podziały na...   \n",
       "\n",
       "     extrovert                                     processed_post  \\\n",
       "0            1  mother told lie dont care actually want feel s...   \n",
       "1            1  couple guys try bully came high school laughed...   \n",
       "2            1  bruh thought meme saw ops replies dumb ways di...   \n",
       "3            1  look girly look boyish talk look like femme fa...   \n",
       "4            1  respect dont see case unless working pretty sp...   \n",
       "..         ...                                                ...   \n",
       "795          0  wanted downvote thought makes wan na move moon...   \n",
       "796          0  best thing leave come back corporations appare...   \n",
       "797          0  believe getting fully psionic pops bit loki li...   \n",
       "798          0  sure even close difficulty seeing obvious red ...   \n",
       "799          0  niestety bdzie dalej betonowa podziay na rynku...   \n",
       "\n",
       "                                       bert_embeddings  \n",
       "0    [-0.0066083446, 0.019449212, 0.45059752, -0.05...  \n",
       "1    [-0.060043834, 0.0022917464, 0.34724408, -0.13...  \n",
       "2    [0.0384882, 1.7724233e-05, 0.51028645, 0.03368...  \n",
       "3    [-0.10429687, 0.14243859, 0.4481033, 0.1055139...  \n",
       "4    [0.025919035, 0.15715231, 0.19118866, -0.01539...  \n",
       "..                                                 ...  \n",
       "795  [-0.09599738, -0.20567349, 0.5923554, -0.21366...  \n",
       "796  [0.05184198, 0.13914925, 0.4454035, -0.0802945...  \n",
       "797  [0.009137345, 0.09711996, 0.3804123, 0.0716632...  \n",
       "798  [-0.0021679848, 0.20878139, 0.35289097, 0.0358...  \n",
       "799  [-0.035595752, 0.015442409, 0.39556208, -0.399...  \n",
       "\n",
       "[800 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sampled_extrovert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5808333333333332\n",
      "Best Hyperparameters: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.56      0.66       117\n",
      "         1.0       0.32      0.63      0.42        38\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.57      0.59      0.54       155\n",
      "weighted avg       0.70      0.57      0.60       155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "225 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.56958333 0.58083333 0.57              nan        nan        nan\n",
      " 0.57708333 0.5725     0.57541667        nan        nan        nan\n",
      " 0.57041667 0.57       0.56916667        nan        nan        nan\n",
      " 0.56333333 0.56333333 0.56375           nan        nan        nan\n",
      " 0.55166667 0.55166667 0.55375           nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Do grid search CV to find best hyperparameters for logistic regression  for extrovert/introvert dichotomy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_sampled_extrovert['bert_embeddings'], data_test['bert_embeddings'], data_sampled_extrovert['extrovert'], data_test['extrovert']\n",
    "X_train_flattened = np.array([embedding.flatten() for embedding in X_train])\n",
    "X_test_flattened = np.array([embedding.flatten() for embedding in X_test])\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l2', 'elasticnet']\n",
    "space['C'] = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# fit best model\n",
    "result = search.fit(X_train_flattened, y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "\n",
    "# calculate classification report on test set\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(X_test_flattened)))\n",
    "\n",
    "# save the predictions of the test set in dataframe with column name 'extrovert_pred'\n",
    "y_pred = result.predict(X_test_flattened)\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df.columns = ['extrovert_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "225 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.56615776 0.57022901 0.56743003        nan        nan        nan\n",
      " 0.57811705 0.57480916 0.57811705        nan        nan        nan\n",
      " 0.60966921 0.60712468 0.60788804        nan        nan        nan\n",
      " 0.62442748 0.62442748 0.62366412        nan        nan        nan\n",
      " 0.6221374  0.62239186 0.62086514        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6244274809160305\n",
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.65      0.73       109\n",
      "         1.0       0.46      0.70      0.55        46\n",
      "\n",
      "    accuracy                           0.66       155\n",
      "   macro avg       0.65      0.67      0.64       155\n",
      "weighted avg       0.72      0.66      0.68       155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "# Do grid search CV to find best hyperparameters for logistic regression  for feeling/thinking dichotomy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_sampled_feeling['bert_embeddings'], data_test['bert_embeddings'], data_sampled_feeling['feeling'], data_test['feeling']\n",
    "X_train_flattened = np.array([embedding.flatten() for embedding in X_train])\n",
    "X_test_flattened = np.array([embedding.flatten() for embedding in X_test])\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l2', 'elasticnet']\n",
    "space['C'] = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# fit the best model\n",
    "result = search.fit(X_train_flattened, y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# calculate classification report on test set\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(X_test_flattened)))\n",
    "\n",
    "# save the predictions of the test set in dataframe with column name 'feeling_pred'\n",
    "y_pred = result.predict(X_test_flattened)\n",
    "y_pred_df['feeling_pred'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "225 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.57012483 0.57240638 0.57149314        nan        nan        nan\n",
      " 0.58788863 0.58516605 0.58743513        nan        nan        nan\n",
      " 0.60063039 0.60290882 0.6017696         nan        nan        nan\n",
      " 0.60769321 0.60769321 0.60837502        nan        nan        nan\n",
      " 0.58469151 0.58469151 0.58446476        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6083750214284602\n",
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.66      0.61        61\n",
      "         1.0       0.75      0.68      0.72        94\n",
      "\n",
      "    accuracy                           0.67       155\n",
      "   macro avg       0.66      0.67      0.66       155\n",
      "weighted avg       0.68      0.67      0.67       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do grid search CV to find best hyperparameters for logistic regression  for judging/perceiving dichotomy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_sampled_judging['bert_embeddings'], data_test['bert_embeddings'], data_sampled_judging['judging'], data_test['judging']\n",
    "X_train_flattened = np.array([embedding.flatten() for embedding in X_train])\n",
    "X_test_flattened = np.array([embedding.flatten() for embedding in X_test])\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l2', 'elasticnet']\n",
    "space['C'] = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X_train_flattened, y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# calculate classification report on test set\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(X_test_flattened)))\n",
    "\n",
    "# save the predictions of the test set in dataframe with column name 'judging_pred'\n",
    "y_pred = result.predict(X_test_flattened)\n",
    "y_pred_df['judging_pred'] = pd.DataFrame(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6207547169811322\n",
      "Best Hyperparameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.58      0.70       137\n",
      "         1.0       0.12      0.44      0.19        18\n",
      "\n",
      "    accuracy                           0.57       155\n",
      "   macro avg       0.51      0.51      0.45       155\n",
      "weighted avg       0.80      0.57      0.65       155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "225 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.53459119 0.52830189 0.53522013        nan        nan        nan\n",
      " 0.54716981 0.54150943 0.5427673         nan        nan        nan\n",
      " 0.57610063 0.57610063 0.57861635        nan        nan        nan\n",
      " 0.61446541 0.61446541 0.61572327        nan        nan        nan\n",
      " 0.62075472 0.62075472 0.62012579        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "# Do grid search CV to find best hyperparameters for logistic regression  for sensing/intuitive dichotomy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_sampled_sensing['bert_embeddings'], data_test['bert_embeddings'], data_sampled_sensing['sensing'], data_test['sensing']\n",
    "X_train_flattened = np.array([embedding.flatten() for embedding in X_train])\n",
    "X_test_flattened = np.array([embedding.flatten() for embedding in X_test])\n",
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l2', 'elasticnet']\n",
    "space['C'] = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X_train_flattened, y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "# calculate classification report on test set\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result.predict(X_test_flattened)))\n",
    "\n",
    "# save the predictions of the test set in dataframe with column name 'sensing_pred'\n",
    "y_pred = result.predict(X_test_flattened)\n",
    "y_pred_df['sensing_pred'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extrovert_pred</th>\n",
       "      <th>feeling_pred</th>\n",
       "      <th>judging_pred</th>\n",
       "      <th>sensing_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     extrovert_pred  feeling_pred  judging_pred  sensing_pred\n",
       "0                 1             1             0             1\n",
       "1                 1             0             0             0\n",
       "2                 0             0             1             1\n",
       "3                 1             1             0             1\n",
       "4                 0             0             0             0\n",
       "..              ...           ...           ...           ...\n",
       "150               1             1             0             1\n",
       "151               0             0             1             0\n",
       "152               1             0             0             1\n",
       "153               0             0             0             1\n",
       "154               0             1             0             0\n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrovert, feeling, judging, sensing transform to int\n",
    "y_pred_df['extrovert_pred'] = y_pred_df['extrovert_pred'].astype(int)\n",
    "y_pred_df['feeling_pred'] = y_pred_df['feeling_pred'].astype(int)\n",
    "y_pred_df['judging_pred'] = y_pred_df['judging_pred'].astype(int)\n",
    "y_pred_df['sensing_pred'] = y_pred_df['sensing_pred'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df['personality'] = y_pred_df['extrovert_pred'].astype(str) + y_pred_df['feeling_pred'].astype(str) + y_pred_df['judging_pred'].astype(str) + y_pred_df['sensing_pred'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrovert, feeling, judging, sensing transform to int\n",
    "data_test['extrovert'] = data_test['extrovert'].astype(int)\n",
    "data_test['feeling'] = data_test['feeling'].astype(int)\n",
    "data_test['judging'] = data_test['judging'].astype(int)\n",
    "data_test['sensing'] = data_test['sensing'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['personality'] = data_test['extrovert'].astype(str) + data_test['feeling'].astype(str) + data_test['judging'].astype(str) + data_test['sensing'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0000       0.00      0.00      0.00         5\n",
      "        0001       0.13      0.14      0.14        14\n",
      "        0010       0.61      0.25      0.35        56\n",
      "        0011       0.00      0.00      0.00         0\n",
      "        0100       0.00      0.00      0.00         8\n",
      "        0101       0.00      0.00      0.00         0\n",
      "        0110       0.45      0.31      0.37        32\n",
      "        0111       0.12      0.50      0.20         2\n",
      "        1000       0.44      0.14      0.21        29\n",
      "        1001       0.00      0.00      0.00         2\n",
      "        1010       0.09      0.33      0.14         3\n",
      "        1011       0.00      0.00      0.00         0\n",
      "        1100       0.00      0.00      0.00         3\n",
      "        1101       0.00      0.00      0.00         0\n",
      "        1110       0.00      0.00      0.00         1\n",
      "        1111       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.21       155\n",
      "   macro avg       0.12      0.10      0.09       155\n",
      "weighted avg       0.41      0.21      0.26       155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dimit\\anaconda3\\envs\\DC3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# calculate classification report on personality prediction\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(data_test['personality'], y_pred_df['personality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 48, 4: 32, 2: 46, 1: 20, 0: 9}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many dichotomies the logistic regression gets right per person\n",
    "\n",
    "distribution = {}\n",
    "\n",
    "for y_actual, y_pred in zip(data_test['personality'], y_pred_df['personality']):\n",
    "    counter = 0\n",
    "    for i in range(4):\n",
    "        if y_actual[i] == y_pred[i]:\n",
    "            counter += 1\n",
    "    \n",
    "    if counter in distribution:\n",
    "        distribution[counter] += 1\n",
    "        \n",
    "    else:\n",
    "        distribution[counter] = 1\n",
    "\n",
    "distribution\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create bar chart for distribution, show as percentages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(distribution.keys(), distribution.values())\n",
    "plt.xticks([0, 1, 2, 3, 4])\n",
    "plt.xlabel('Number of correct predictions')\n",
    "plt.ylabel('Number of users')\n",
    "plt.ylim(0, 70)\n",
    "plt.title('Distribution of correct personality predictions')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5161290322580645"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of getting 3-4 correct\n",
    "\n",
    "(distribution[3] + distribution[4]) / sum(distribution.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
